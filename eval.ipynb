{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from env.mec_offloaing_envs.offloading_env import Resources\n",
    "from env.mec_offloaing_envs.offloading_env import OffloadingEnvironment\n",
    "from models import GraphSeq2Seq, BaselineSeq2Seq\n",
    "from buffer import RolloutBuffer\n",
    "from train import inner_loop\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "if args[\"wandb\"]:\n",
    "    import wandb\n",
    "    wandb.login(key=args[\"wandb_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = Resources(mec_process_capable=args[\"mec_process_capable\"]*1024*1024,\n",
    "                        mobile_process_capable=args[\"mobile_process_capable\"]*1024*1024,\n",
    "                        bandwidth_up=args[\"bandwidth_up\"],\n",
    "                        bandwidth_dl=args[\"bandwidth_down\"])\n",
    "\n",
    "env = OffloadingEnvironment(resource_cluster=resources,\n",
    "                            batch_size=args['graph_number'],\n",
    "                            graph_number=args['graph_number'],\n",
    "                            graph_file_paths=[\"./env/mec_offloaing_envs/data/meta_offloading_20/offload_random20_12/random.20.\"],\n",
    "                            time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"wandb\"]:\n",
    "    wandb.init(project=\"mec-offloading-phase-1\",\n",
    "            name='experiment',\n",
    "            config=args)\n",
    "\n",
    "print(f'Average greedy latency: {np.mean(env.greedy_solution()[1]):.4f}')\n",
    "print(f'Average all local latency: {np.mean(env.get_all_locally_execute_time()):.4f}')\n",
    "print(f'Average all mec latency: {np.mean(env.get_all_mec_execute_time()):.4f}')\n",
    "\n",
    "inner_lr = args[\"inner_lr\"]\n",
    "outer_lr = args[\"outer_lr\"]\n",
    "adapt_steps = args[\"adaptation_steps\"]\n",
    "inner_bs = args[\"inner_batch_size\"]\n",
    "meta_batch_size = 1\n",
    "num_iterations = args[\"num_iterations\"]\n",
    "vf_coef = args[\"vf_coef\"]\n",
    "vf_is_clipped = args[\"vf_is_clipped\"]\n",
    "ent_coef = args[\"ent_coef\"]\n",
    "clip_eps = args[\"clip_eps\"]\n",
    "is_graph = args[\"is_graph\"]\n",
    "device = args[\"device\"]\n",
    "num_task_episodes = args[\"num_task_episodes\"]\n",
    "gamma = args[\"gamma\"]\n",
    "tau = args[\"tau\"]\n",
    "graph_number = args[\"graph_number\"]\n",
    "latencies = []\n",
    "\n",
    "if is_graph:\n",
    "    policy = GraphSeq2Seq(15, 128, 2, 2, device).to(device)\n",
    "else:\n",
    "    policy = BaselineSeq2Seq(15, 128, 2, 2, device).to(device)\n",
    "if args[\"load\"]:\n",
    "    policy.load_state_dict(torch.load(args[\"load_path\"]))\n",
    "buffer = RolloutBuffer(meta_batch_size, graph_number*num_task_episodes, discount=gamma, gae_lambda=tau, device=device)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=inner_lr)\n",
    "\n",
    "for iteration in tqdm(range(num_iterations), leave=False, disable=True):\n",
    "    task_policies = []\n",
    "    fts_before, fts_after = [], []\n",
    "    vf_losses, pg_losses, ent_losses = [], [], []\n",
    "    all_rewards, all_returns = [], []\n",
    "    \n",
    "    batch_of_tasks = env.sample_tasks(meta_batch_size)\n",
    "\n",
    "    buffer.reset()\n",
    "    print('sampling trajectories')\n",
    "    for i, task_id in enumerate(batch_of_tasks):\n",
    "        buffer.collect_episodes(env, policy, device, i, task_id, is_graph)\n",
    "    buffer.process()\n",
    "    \n",
    "    for i, task_id in enumerate(batch_of_tasks):\n",
    "        vf_loss, pg_loss, ent_loss, fts, policy = inner_loop(policy, optimizer, buffer, i, task_id, inner_bs, adapt_steps, clip_eps, vf_coef, ent_coef, vf_is_clipped, is_graph)\n",
    "        vf_losses.append(vf_loss)\n",
    "        pg_losses.append(pg_loss)\n",
    "        ent_losses.append(ent_loss)\n",
    "        fts_before.append(fts)\n",
    "        task_policies.append(policy)\n",
    "\n",
    "    print('*'*50)\n",
    "    latencies.append(np.mean(np.concatenate(fts_before)))\n",
    "    print(\"Iteration\", iteration,\n",
    "        \"| vf_loss: {:.4f}\".format(np.mean(vf_losses)),\n",
    "        \"| pg_loss: {:.4f}\".format(np.mean(pg_losses)),\n",
    "        \"| ent_loss: {:.4f}\".format(np.mean(ent_losses)),\n",
    "        \"| average_reward: {:.4f}\".format(np.mean([reward.sum(-1) for reward in buffer.rewards])),\n",
    "        \"| average_return: {:.4f}\".format(np.mean([returns[:, 0].mean().item() for returns in buffer.returns])),\n",
    "        \"| latency before adaptation: {:.4f}\".format(np.mean(np.concatenate(fts_before))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
