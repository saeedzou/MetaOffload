{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from env.mec_offloaing_envs.offloading_env import Resources\n",
    "from env.mec_offloaing_envs.offloading_env import OffloadingEnvironment\n",
    "from models import GraphSeq2Seq, BaselineSeq2Seq\n",
    "from buffer import RolloutBuffer\n",
    "from train import inner_loop\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x214b507ca90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('my_config.json') as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "class Config:\n",
    "        def __init__(self, dictionary):\n",
    "            for key, value in dictionary.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "c = Config(args)\n",
    "\n",
    "np.random.seed(c.seed)\n",
    "torch.manual_seed(c.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading graph offload_random20_12: 100%|██████████| 100/100 [00:19<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "resources = Resources(mec_process_capable=c.mec_process_capable*10e9,\n",
    "                      mobile_process_capable=c.mobile_process_capable*10e9,\n",
    "                      bandwidth_up=c.bandwidth_up,\n",
    "                      bandwidth_dl=c.bandwidth_down)\n",
    "\n",
    "env = OffloadingEnvironment(resource_cluster=resources,\n",
    "                            batch_size=c.graph_number,\n",
    "                            graph_number=c.graph_number,\n",
    "                            graph_file_paths=[\"./env/mec_offloaing_envs/data/meta_offloading_20/offload_random20_12/random.20.\"],\n",
    "                            time_major=False,\n",
    "                            encoding=\"rank_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average greedy latency: 0.1550\n"
     ]
    }
   ],
   "source": [
    "print(f'Average greedy latency: {np.mean(env.greedy_solution()[1]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average greedy latency: 808.9166\n"
     ]
    }
   ],
   "source": [
    "print(f'Average greedy latency: {np.mean(env.greedy_solution()[1]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.        ,  0.7481408 ,  0.8561118 , ...,  0.8       ,\n",
       "           0.9       , -1.        ],\n",
       "         [ 0.05      ,  0.65810084,  0.75320905, ...,  0.8       ,\n",
       "           0.9       ,  0.95      ],\n",
       "         [ 0.2       ,  0.38986847,  0.44665775, ...,  0.95      ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.8       ,  0.36082217,  0.413462  , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.55      ,  0.21686661,  0.24894135, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.75      ,  0.19556251,  0.2245938 , ..., -1.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.8741706 ,  1.        , ...,  0.9       ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.35      ,  0.78471947,  0.89777017, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.05      ,  0.6425662 ,  0.73530924, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.95      ,  0.36101905,  0.41354108, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.65      ,  0.18078281,  0.2075568 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.9       ,  0.17641534,  0.2025654 , ..., -1.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.05      ,  0.87429315,  1.        , ...,  0.65      ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.1       ,  0.83093864,  0.95045197, ...,  0.65      ,\n",
       "           0.8       , -1.        ],\n",
       "         [ 0.3       ,  0.8610944 ,  0.9849157 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.9       ,  0.44774282,  0.5125139 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.85      ,  0.395703  ,  0.4530398 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.95      ,  0.10110436,  0.11635564, ..., -1.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.15      ,  0.7524432 ,  0.86126363, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.05      ,  0.6117567 ,  0.70047903, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  0.39422688,  0.45187357, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.9       ,  0.252112  ,  0.28945655, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.25      ,  0.1668973 ,  0.19206832, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.75      ,  0.10457287,  0.12084041, ..., -1.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.4       ,  0.87456256,  1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.35      ,  0.84505343,  0.9662753 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.65      ,  0.7328838 ,  0.8380815 , ...,  0.95      ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.9       ,  0.14558247,  0.16687992, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  0.1304263 ,  0.14955859, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.95      ,  0.1205259 ,  0.13824385, ..., -1.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.8528408 ,  0.97545385, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.1       ,  0.21196146,  0.24302034, ...,  0.55      ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.2       ,  0.19456778,  0.22314185, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.95      ,  0.347385  ,  0.39779007, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.9       ,  0.16522603,  0.1896084 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.7       ,  0.15057305,  0.17286214, ..., -1.        ,\n",
       "          -1.        , -1.        ]]], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.encoder_batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average greedy latency: 808.9166\n",
      "Average all local latency: 1478.0573\n",
      "Average all mec latency: 1052.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Iteration 0 | vf_loss: 4.5034 | pg_loss: -0.0050 | ent_loss: 0.6881 | average_reward: -5.9766 | average_return: -5.5198 | latency before adaptation: 896.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(f'Average greedy latency: {np.mean(env.greedy_solution()[1]):.4f}')\n",
    "print(f'Average all local latency: {np.mean(env.get_all_locally_execute_time()):.4f}')\n",
    "print(f'Average all mec latency: {np.mean(env.get_all_mec_execute_time()):.4f}')\n",
    "\n",
    "device = c.device\n",
    "c.meta_batch_size = 1\n",
    "latencies = []\n",
    "\n",
    "if c.is_graph:\n",
    "    policy = GraphSeq2Seq(input_dim=c.obs_dim,\n",
    "                          hidden_dim=c.encoder_units,\n",
    "                          output_dim=c.action_dim,\n",
    "                          num_layers=c.num_layers,\n",
    "                          device=device).to(device)\n",
    "else:\n",
    "    policy = BaselineSeq2Seq(input_dim=c.obs_dim,\n",
    "                             hidden_dim=c.encoder_units,\n",
    "                             output_dim=c.action_dim,\n",
    "                             num_layers=c.num_layers,\n",
    "                             device=device).to(device)\n",
    "if args[\"load\"]:\n",
    "    policy.load_state_dict(torch.load(args[\"load_path\"]))\n",
    "\n",
    "buffer = RolloutBuffer(meta_batch_size=c.meta_batch_size, \n",
    "                       buffer_size=c.graph_number*c.num_task_episodes, \n",
    "                       discount=c.gamma, \n",
    "                       gae_lambda=c.tau, \n",
    "                       device=device)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=c.inner_lr)\n",
    "\n",
    "for iteration in tqdm(range(0, 1), leave=False, disable=True):\n",
    "    task_policies = []\n",
    "    fts_before, fts_after = [], []\n",
    "    vf_losses, pg_losses, ent_losses = [], [], []\n",
    "    all_rewards, all_returns = [], []\n",
    "    \n",
    "    batch_of_tasks = env.sample_tasks(c.meta_batch_size)\n",
    "\n",
    "\n",
    "    ### Sample trajectories ###\n",
    "    buffer.reset()\n",
    "    for i, task_id in tqdm(enumerate(batch_of_tasks), leave=False, total=c.meta_batch_size, desc=f'Sampling trajectories'):\n",
    "        buffer.collect_episodes(env=env, \n",
    "                                policy=policy, \n",
    "                                device=device, \n",
    "                                meta_batch=i, \n",
    "                                task_id=task_id, \n",
    "                                is_graph=c.is_graph)\n",
    "    buffer.process()\n",
    "    \n",
    "    for i, task_id in enumerate(batch_of_tasks):\n",
    "        vf_loss, pg_loss, ent_loss, fts, policy = \\\n",
    "            inner_loop(policy=policy, \n",
    "                       optimizer=optimizer, \n",
    "                       buffer=buffer, \n",
    "                       meta_batch=i, \n",
    "                       task_id=task_id, \n",
    "                       hparams=c)\n",
    "        vf_losses.append(vf_loss)\n",
    "        pg_losses.append(pg_loss)\n",
    "        ent_losses.append(ent_loss)\n",
    "        fts_before.append(fts)\n",
    "        task_policies.append(policy)\n",
    "\n",
    "    print('*'*50)\n",
    "    latencies.append(np.mean(np.concatenate(fts_before)))\n",
    "    print(\"Iteration\", iteration,\n",
    "        \"| vf_loss: {:.4f}\".format(np.mean(vf_losses)),\n",
    "        \"| pg_loss: {:.4f}\".format(np.mean(pg_losses)),\n",
    "        \"| ent_loss: {:.4f}\".format(np.mean(ent_losses)),\n",
    "        \"| average_reward: {:.4f}\".format(np.mean([reward.sum(-1) for reward in buffer.rewards])),\n",
    "        \"| average_return: {:.4f}\".format(np.mean([returns[:, 0].mean().item() for returns in buffer.returns])),\n",
    "        \"| latency before adaptation: {:.4f}\".format(np.mean(np.concatenate(fts_before))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.84362584,  0.3742647 , ...,  0.8       ,\n",
       "          0.9       , -1.        ],\n",
       "        [ 0.05      ,  0.73179364,  0.31834856, ...,  0.8       ,\n",
       "          0.9       ,  0.95      ],\n",
       "        [ 0.2       ,  0.39864117,  0.15177234, ...,  0.95      ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.8       ,  0.36256486,  0.13373418, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.55      ,  0.18376783,  0.04433567, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.75      ,  0.15730752,  0.03110552, ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 0.        ,  1.        ,  0.24297327, ...,  0.9       ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.35      ,  0.8901705 ,  0.21002443, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.05      ,  0.71563256,  0.15766305, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.95      ,  0.36994463,  0.05395667, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.65      ,  0.14864783, -0.01243238, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.9       ,  0.14328536, -0.01404112, ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 0.05      ,  1.        ,  0.25192836, ...,  0.65      ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.1       ,  0.94734704,  0.23613246, ...,  0.65      ,\n",
       "          0.8       , -1.        ],\n",
       "        [ 0.3       ,  0.98397046,  0.24711949, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.9       ,  0.48196566,  0.09651805, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.85      ,  0.41876462,  0.07755774, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.95      ,  0.06098222, -0.02977698, ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.15      ,  0.8463633 ,  0.36433223, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.05      ,  0.6683104 ,  0.27530578, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.39300466,  0.13765289, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.9       ,  0.21314402,  0.04772257, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.25      ,  0.10529628, -0.0062013 , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.75      ,  0.02641846, -0.04564021, ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 0.4       ,  1.        ,  0.27094176, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.35      ,  0.9649978 ,  0.26044112, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.65      ,  0.8319481 ,  0.22052619, ...,  0.95      ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.9       ,  0.13532177,  0.01153829, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.        ,  0.11734431,  0.00614506, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.95      ,  0.10560098,  0.00262206, ..., -1.        ,\n",
       "         -1.        , -1.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.9739745 ,  0.34996158, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.1       ,  0.19739875,  0.03933128, ...,  0.55      ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.2       ,  0.17632222,  0.03090067, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.95      ,  0.36149615,  0.10497024, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.9       ,  0.14076778,  0.01667889, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.7       ,  0.12301227,  0.00957669, ..., -1.        ,\n",
       "         -1.        , -1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.observations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = nn.Linear(10, 2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "x = torch.randn(100, 10)\n",
    "y = torch.randint(0, 2, (100,))\n",
    "opt_states = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    opt_states.append(optimizer.state_dict())\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'capturable': False,\n",
       "   'differentiable': False,\n",
       "   'fused': None,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6051, -0.5528,  0.2216, -0.4529,  0.3433, -0.0203,  0.4645, -0.0500,\n",
       "         -0.4121, -0.2808],\n",
       "        [-0.1735, -0.5906,  0.3890, -0.4964,  0.1963,  0.3686,  0.3746, -0.3546,\n",
       "         -0.3248, -0.4352]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "def linear_init(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "    if module.bias is not None:\n",
    "        nn.init.constant_(module.bias, 0)\n",
    "    return module\n",
    "x = nn.Linear(10, 2)\n",
    "y = linear_init(nn.Linear(10, 2))\n",
    "y.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2456,  0.2074, -0.1387, -0.1093,  0.2080, -0.0609,  0.2578,  0.2012,\n",
       "          0.1854,  0.0672],\n",
       "        [-0.3058,  0.2043, -0.0009,  0.0798, -0.0257, -0.1717,  0.2533,  0.0942,\n",
       "         -0.2720,  0.2637]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
